"""
STEP 4: Community Detection
Input: NetworkX graph
Output: List of communities (clusters of related entities)
"""

from typing import List
import networkx as nx
from cdlib import algorithms
from config import MIN_COMMUNITY_SIZE


class CommunityOutput:
    """Output c·ªßa b∆∞·ªõc community detection"""
    def __init__(self, communities: List[List[str]], stats: dict):
        self.communities = communities
        self.stats = stats
    
    def print_summary(self):
        print("\n" + "=" * 80)
        print("STEP 4: COMMUNITY DETECTION - OUTPUT")
        print("=" * 80)
        print(f"üì• S·ªë nodes trong graph: {self.stats['num_nodes']}")
        print(f"üì• S·ªë edges trong graph: {self.stats['num_edges']}")
        print(f"üåê S·ªë connected components: {self.stats['num_components']}")
        print(f"üë• T·ªïng s·ªë communities ph√°t hi·ªán: {self.stats['total_communities']}")
        print(f"‚≠ê S·ªë communities l·ªõn (>={MIN_COMMUNITY_SIZE} nodes): {self.stats['large_communities']}")
        
        print(f"\nüìä Ph√¢n b·ªë k√≠ch th∆∞·ªõc communities:")
        for size, count in sorted(self.stats['size_distribution'].items()):
            print(f"   - Size {size}: {count} communities")
        
        print(f"\nüìã Top 5 communities l·ªõn nh·∫•t:")
        for i, comm in enumerate(self.communities[:5]):
            print(f"   {i+1}. [{len(comm)} nodes] {', '.join(comm[:5])}{'...' if len(comm) > 5 else ''}")
        
        print("=" * 80)
    
    def save_to_file(self, output_dir: str = "pipeline_outputs"):
        """L∆∞u output ra file txt"""
        import os
        os.makedirs(output_dir, exist_ok=True)
        
        filepath = os.path.join(output_dir, "step4_communities_output.txt")
        with open(filepath, "w", encoding="utf-8") as f:
            f.write("=" * 80 + "\n")
            f.write("STEP 4: COMMUNITY DETECTION - DETAILED OUTPUT\n")
            f.write("=" * 80 + "\n\n")
            
            # Stats
            f.write("üìä TH·ªêNG K√ä:\n")
            f.write(f"   - S·ªë nodes trong graph: {self.stats['num_nodes']}\n")
            f.write(f"   - S·ªë edges trong graph: {self.stats['num_edges']}\n")
            f.write(f"   - S·ªë connected components: {self.stats['num_components']}\n")
            f.write(f"   - T·ªïng s·ªë communities: {self.stats['total_communities']}\n")
            f.write(f"   - Communities l·ªõn (>={MIN_COMMUNITY_SIZE}): {self.stats['large_communities']}\n\n")
            
            f.write("üìä PH√ÇN B·ªê K√çCH TH∆Ø·ªöC:\n")
            for size, count in sorted(self.stats['size_distribution'].items()):
                f.write(f"   - Size {size}: {count} communities\n")
            
            # All communities
            f.write("\n" + "=" * 80 + "\n")
            f.write(f"üìù T·∫§T C·∫¢ COMMUNITIES ({len(self.communities)} communities):\n")
            f.write("=" * 80 + "\n\n")
            
            for i, comm in enumerate(self.communities, 1):
                f.write(f"--- COMMUNITY {i} (Size: {len(comm)}) ---\n")
                for j, entity in enumerate(comm, 1):
                    f.write(f"   {j}. {entity}\n")
                f.write("\n")
        
        print(f"üíæ ƒê√£ l∆∞u output v√†o: {filepath}")
        return filepath


class CommunityDetector:
    """Class ƒë·ªÉ ph√°t hi·ªán communities trong graph"""
    
    def detect(self, graph: nx.Graph) -> CommunityOutput:
        """
        Ph√°t hi·ªán communities s·ª≠ d·ª•ng Leiden algorithm
        
        Args:
            graph: NetworkX graph
            
        Returns:
            CommunityOutput: Object ch·ª©a communities v√† stats
        """
        communities = []
        
        # X·ª≠ l√Ω t·ª´ng connected component
        for component in nx.connected_components(graph):
            if len(component) > 2:
                # Component ƒë·ªß l·ªõn -> d√πng Leiden
                subgraph = graph.subgraph(component)
                try:
                    comms = algorithms.leiden(subgraph)
                    communities.extend([list(c) for c in comms.communities])
                except Exception as e:
                    # N·∫øu Leiden th·∫•t b·∫°i, coi c·∫£ component l√† 1 community
                    print(f"[WARN] Leiden failed for component size {len(component)}: {e}")
                    communities.append(list(component))
            else:
                # Component nh·ªè -> coi l√† 1 community
                communities.append(list(component))
        
        # L·ªçc communities l·ªõn
        large_communities = [c for c in communities if len(c) >= MIN_COMMUNITY_SIZE]
        
        # N·∫øu kh√¥ng c√≥ community l·ªõn, gi·ªØ t·∫•t c·∫£
        if not large_communities:
            large_communities = communities
        
        # S·∫Øp x·∫øp theo k√≠ch th∆∞·ªõc gi·∫£m d·∫ßn
        large_communities.sort(key=len, reverse=True)
        
        # T√≠nh to√°n stats
        size_distribution = {}
        for comm in communities:
            size = len(comm)
            size_distribution[size] = size_distribution.get(size, 0) + 1
        
        stats = {
            'num_nodes': graph.number_of_nodes(),
            'num_edges': graph.number_of_edges(),
            'num_components': nx.number_connected_components(graph),
            'total_communities': len(communities),
            'large_communities': len(large_communities),
            'size_distribution': size_distribution,
            'avg_community_size': sum(len(c) for c in large_communities) / len(large_communities) if large_communities else 0
        }
        
        return CommunityOutput(large_communities, stats)


if __name__ == "__main__":
    # Test community detection
    G = nx.Graph()
    
    # T·∫°o graph test v·ªõi 2 communities r√µ r√†ng
    # Community 1: OS-related
    G.add_edge("H·ªá ƒëi·ªÅu h√†nh", "Ti·∫øn tr√¨nh")
    G.add_edge("H·ªá ƒëi·ªÅu h√†nh", "B·ªô nh·ªõ")
    G.add_edge("Ti·∫øn tr√¨nh", "CPU")
    G.add_edge("B·ªô nh·ªõ", "CPU")
    
    # Community 2: Programming-related
    G.add_edge("Python", "Django")
    G.add_edge("Python", "Flask")
    G.add_edge("Django", "Web Framework")
    
    detector = CommunityDetector()
    output = detector.detect(G)
    output.print_summary()