"""
STEP 5: Answer Generation
Input: Communities and user query
Output: Final answer generated by LLM
"""

from typing import List
from openai import OpenAI
from config import ANSWER_MAX_TOKENS, MAX_COMMUNITIES_FOR_ANSWER


class AnswerOutput:
    """Output c·ªßa b∆∞·ªõc answer generation"""
    def __init__(self, answer: str, stats: dict):
        self.answer = answer
        self.stats = stats
    
    def print_summary(self):
        print("\n" + "=" * 80)
        print("STEP 5: ANSWER GENERATION - OUTPUT")
        print("=" * 80)
        print(f"‚ùì Query: {self.stats['query']}")
        print(f"üë• S·ªë communities s·ª≠ d·ª•ng: {self.stats['num_communities_used']}")
        print(f"üìù ƒê·ªô d√†i context: {self.stats['context_length']} k√Ω t·ª±")
        print(f"ü§ñ Model: {self.stats['model']}")
        print(f"üìä ƒê·ªô d√†i answer: {self.stats['answer_length']} k√Ω t·ª±")
        print("\n" + "=" * 80)
        print("FINAL ANSWER")
        print("=" * 80)
        print(self.answer)
        print("=" * 80)
    
    def save_to_file(self, output_dir: str = "pipeline_outputs"):
        """L∆∞u output ra file txt"""
        import os
        os.makedirs(output_dir, exist_ok=True)
        
        filepath = os.path.join(output_dir, "step5_answer_output.txt")
        with open(filepath, "w", encoding="utf-8") as f:
            f.write("=" * 80 + "\n")
            f.write("STEP 5: ANSWER GENERATION - DETAILED OUTPUT\n")
            f.write("=" * 80 + "\n\n")
            
            # Stats
            f.write("üìä TH·ªêNG K√ä:\n")
            f.write(f"   - Query: {self.stats['query']}\n")
            f.write(f"   - S·ªë communities s·ª≠ d·ª•ng: {self.stats['num_communities_used']}\n")
            f.write(f"   - ƒê·ªô d√†i context: {self.stats['context_length']} k√Ω t·ª±\n")
            f.write(f"   - Model: {self.stats['model']}\n")
            f.write(f"   - ƒê·ªô d√†i answer: {self.stats['answer_length']} k√Ω t·ª±\n\n")
            
            # Answer
            f.write("=" * 80 + "\n")
            f.write("üìù C√ÇU TR·∫¢ L·ªúI CU·ªêI C√ôNG:\n")
            f.write("=" * 80 + "\n\n")
            f.write(self.answer)
            f.write("\n\n")
        
        print(f"üíæ ƒê√£ l∆∞u output v√†o: {filepath}")
        return filepath


class AnswerGenerator:
    """Class ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi t·ª´ communities"""
    
    SYSTEM_PROMPT = """D·ª±a tr√™n c√°c nh√≥m kh√°i ni·ªám v√† quan h·ªá, h√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch chi ti·∫øt b·∫±ng ti·∫øng Vi·ªát.

H∆∞·ªõng d·∫´n:
- S·ª≠ d·ª•ng th√¥ng tin t·ª´ c√°c nh√≥m ki·∫øn th·ª©c ƒë∆∞·ª£c cung c·∫•p
- Tr·∫£ l·ªùi tr·ª±c ti·∫øp v√† s√∫c t√≠ch
- N·∫øu th√¥ng tin kh√¥ng ƒë·ªß, h√£y n√≥i r√µ
- C·∫•u tr√∫c c√¢u tr·∫£ l·ªùi logic v√† d·ªÖ hi·ªÉu
"""
    
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)
    
    def _format_communities(self, communities: List[List[str]]) -> str:
        """Format communities th√†nh text ƒë·ªÉ ƒë∆∞a v√†o LLM"""
        comm_descriptions = []
        
        # Ch·ªâ l·∫•y s·ªë l∆∞·ª£ng communities gi·ªõi h·∫°n
        selected_communities = communities[:MAX_COMMUNITIES_FOR_ANSWER]
        
        for i, comm in enumerate(selected_communities):
            # L·∫•y t·ªëi ƒëa 10 entities ƒë·∫ßu ti√™n c·ªßa m·ªói community
            entities = ', '.join(comm[:10])
            if len(comm) > 10:
                entities += f" ... (+{len(comm) - 10} entities kh√°c)"
            
            comm_descriptions.append(f"Nh√≥m {i+1}: {entities}")
        
        return "\n".join(comm_descriptions)
    
    def generate(self, communities: List[List[str]], query: str) -> AnswerOutput:
        """
        T·∫°o c√¢u tr·∫£ l·ªùi d·ª±a tr√™n communities v√† query
        
        Args:
            communities: List of communities (m·ªói community l√† list of entity names)
            query: User's question
            
        Returns:
            AnswerOutput: Object ch·ª©a answer v√† stats
        """
        # Format communities th√†nh context
        context = self._format_communities(communities)
        
        # T·∫°o prompt
        user_prompt = f"""
C√¢u h·ªèi: {query}

C√°c nh√≥m ki·∫øn th·ª©c ch√≠nh:
{context}
"""
        
        # G·ªçi LLM
        response = self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": self.SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=ANSWER_MAX_TOKENS
        )
        
        answer = response.choices[0].message.content
        
        # T√≠nh to√°n stats
        stats = {
            'query': query,
            'num_communities_used': min(len(communities), MAX_COMMUNITIES_FOR_ANSWER),
            'context_length': len(context),
            'model': 'gpt-4o',
            'answer_length': len(answer)
        }
        
        return AnswerOutput(answer, stats)