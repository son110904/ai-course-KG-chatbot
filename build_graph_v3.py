# build_graph_complete.py
"""
COMPLETE KNOWLEDGE GRAPH BUILDER
Unified system for both GraphRAG Query and Career Advisor
Loads all data from MinIO: curriculum, syllabus, career descriptions
"""

from openai import OpenAI
from dotenv import load_dotenv
import os
import time

from minio_loader_v3 import MinioLoaderV3
from graph_database import GraphDatabaseConnection
from graph_manager_v3 import GraphManagerV3
from logger import Logger

# =========================================================
# CONFIGURATION
# =========================================================
load_dotenv()

logger = Logger("BuildCompleteGraph").get_logger()

# MinIO Configuration
MINIO_ENDPOINT = os.getenv("MINIO_ENDPOINT", "203.113.132.48:8008")
MINIO_ACCESS_KEY = os.getenv("MINIO_ACCESS_KEY", "course2")
MINIO_SECRET_KEY = os.getenv("MINIO_SECRET_KEY", "course2-s3-uiauia")
MINIO_BUCKET = os.getenv("MINIO_BUCKET_NAME", "syllabus")
MINIO_SECURE = os.getenv("MINIO_SECURE", "false").lower() == "true"

# ALL folders - Complete system
MINIO_FOLDERS = [
    "courses-processed/curriculum/",         # Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o (for both)
    "courses-processed/syllabus/",          # ƒê·ªÅ c∆∞∆°ng h·ªçc ph·∫ßn (for GraphRAG)
    "courses-processed/career_description/" # M√¥ t·∫£ ngh·ªÅ nghi·ªáp (for Career Advisor)
]

# OpenAI Configuration
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY must be set in .env file")

MODEL = os.getenv("MODEL", "gpt-4o-mini")
MAX_WORKERS = int(os.getenv("MAX_WORKERS", "10"))

# Neo4j Configuration
DB_URL = os.getenv("DB_URL")
DB_USERNAME = os.getenv("DB_USERNAME", "neo4j")
DB_PASSWORD = os.getenv("DB_PASSWORD")

if not DB_URL or not DB_PASSWORD:
    raise ValueError("Neo4j credentials must be set in .env file")

# Processing Configuration
CHUNK_SIZE = int(os.getenv("CHUNK_SIZE", "2000"))
OVERLAP_SIZE = int(os.getenv("OVERLAP_SIZE", "300"))

# =========================================================
# PROCESSING PIPELINE
# =========================================================

def build_complete_knowledge_graph(cache_prefix="complete_graph"):
    """
    Build complete knowledge graph for:
    1. GraphRAG - Query answering system
    2. Career Advisor - Career guidance system
    
    Loads all data from MinIO and creates unified graph.
    """
    
    start_time = time.time()
    
    logger.info("=" * 80)
    logger.info("COMPLETE KNOWLEDGE GRAPH BUILDER")
    logger.info("=" * 80)
    logger.info("Building unified graph for:")
    logger.info("  ‚úì GraphRAG Query System")
    logger.info("  ‚úì Career Advisor Chatbot")
    logger.info("=" * 80)
    
    # Initialize OpenAI client
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    # Check Neo4j database status
    db_connection = GraphDatabaseConnection(
        uri=DB_URL,
        user=DB_USERNAME,
        password=DB_PASSWORD
    )
    
    stats = db_connection.get_database_stats()
    has_data = stats['nodes'] > 0 or stats['relationships'] > 0
    
    if has_data:
        print(f"\n‚ö†Ô∏è  WARNING: Database already contains data!")
        print(f"   Nodes: {stats['nodes']}")
        print(f"   Relationships: {stats['relationships']}")
        print(f"\n   Options:")
        print(f"   1. Clear and rebuild (all existing data will be lost)")
        print(f"   2. Add to existing data (may create duplicates)")
        print(f"   3. Skip and use existing data")
        print(f"   4. Cancel")
        
        choice = input("\n   Enter your choice (1/2/3/4): ").strip()
        
        if choice == "1":
            logger.info("User chose to clear and rebuild database")
            auto_clear = True
        elif choice == "2":
            logger.info("User chose to add to existing data")
            auto_clear = False
        elif choice == "3":
            logger.info("User chose to skip and use existing data")
            db_connection.close()
            return {
                'documents': 0,
                'chunks': 0,
                'elements': 0,
                'graph': stats,
                'time': 0,
                'skipped': True
            }
        else:
            logger.info("User cancelled operation")
            db_connection.close()
            return None
    else:
        auto_clear = False
        logger.info("Database is empty, proceeding with data loading...")
    
    # Initialize MinIO loader V3
    minio_loader = MinioLoaderV3(
        endpoint=MINIO_ENDPOINT,
        access_key=MINIO_ACCESS_KEY,
        secret_key=MINIO_SECRET_KEY,
        bucket_name=MINIO_BUCKET,
        client=client,
        model=MODEL,
        max_workers=MAX_WORKERS,
        secure=MINIO_SECURE
    )
    
    # Initialize graph manager V3
    graph_manager = GraphManagerV3(
        db_connection=db_connection,
        auto_clear=auto_clear,
        openai_client=client
    )
    
    # Step 1: Load documents from MinIO
    logger.info(f"[1/5] Loading ALL documents from MinIO...")
    logger.info(f"  Endpoint: {MINIO_ENDPOINT}")
    logger.info(f"  Bucket: {MINIO_BUCKET}")
    logger.info(f"  Folders:")
    for folder in MINIO_FOLDERS:
        logger.info(f"    - {folder}")
    
    documents = minio_loader.load_documents_from_folders(MINIO_FOLDERS)
    
    if not documents:
        logger.error("No documents loaded from MinIO")
        db_connection.close()
        return None
    
    logger.info(f"  ‚úì Loaded {len(documents)} documents")
    
    # Analyze document types
    doc_types = {}
    for doc in documents:
        doc_type = doc.get('document_type', 'unknown')
        doc_types[doc_type] = doc_types.get(doc_type, 0) + 1
    
    logger.info(f"  Document types breakdown:")
    for doc_type, count in doc_types.items():
        logger.info(f"    - {doc_type}: {count}")
    
    # Validate data completeness
    has_syllabus = any('syllabus' in dt.lower() for dt in doc_types.keys())
    has_curriculum = any('curriculum' in dt.lower() for dt in doc_types.keys())
    has_career = any('career' in dt.lower() for dt in doc_types.keys())
    
    logger.info(f"\n  Data completeness check:")
    logger.info(f"    {'‚úì' if has_syllabus else '‚úó'} Syllabus data (for GraphRAG queries)")
    logger.info(f"    {'‚úì' if has_curriculum else '‚úó'} Curriculum data (for both systems)")
    logger.info(f"    {'‚úì' if has_career else '‚úó'} Career descriptions (for Career Advisor)")
    
    if not has_career:
        logger.warning("\n  ‚ö†Ô∏è  WARNING: No career description data found!")
        logger.warning("     Career Advisor will have limited functionality.")
        logger.warning("     Make sure 'career description' folder has JSON files.")
    
    # Step 2: Smart Chunking
    logger.info(f"\n[2/5] Creating intelligent chunks...")
    chunks = minio_loader.split_documents(
        documents,
        chunk_size=CHUNK_SIZE,
        overlap_size=OVERLAP_SIZE
    )
    logger.info(f"  ‚úì Created {len(chunks)} chunks")
    
    # Log chunk type distribution
    chunk_types = {}
    for chunk in chunks:
        chunk_type = chunk.get('chunk_type', 'unknown')
        chunk_types[chunk_type] = chunk_types.get(chunk_type, 0) + 1
    
    logger.info(f"  Chunk types:")
    for chunk_type, count in chunk_types.items():
        logger.info(f"    - {chunk_type}: {count}")
    
    # Step 3: Entity & Relation Extraction
    logger.info(f"\n[3/5] Extracting entities & relations with LLM...")
    logger.info(f"  This may take 10-30 minutes for {len(chunks)} chunks...")
    logger.info(f"  Using {MAX_WORKERS} parallel workers")
    
    elements = minio_loader.load_or_process(
        f"data/{cache_prefix}_elements.pkl",
        minio_loader.extract_elements,
        chunks,
        use_parallel=True
    )
    logger.info(f"  ‚úì Extracted {len(elements)} element sets")
    
    # Log extraction stats
    total_entities = sum(len(e.get('entities', [])) for e in elements)
    total_relations = sum(len(e.get('relations', [])) for e in elements)
    logger.info(f"  Extraction statistics:")
    logger.info(f"    - Total entities: {total_entities}")
    logger.info(f"    - Total relations: {total_relations}")
    logger.info(f"    - Avg entities per chunk: {total_entities/len(chunks):.1f}")
    logger.info(f"    - Avg relations per chunk: {total_relations/len(chunks):.1f}")
    
    # Step 4: Build Graph
    logger.info(f"\n[4/5] Building unified knowledge graph...")
    graph_stats = graph_manager.build_graph_from_elements(elements)
    logger.info(f"  ‚úì Graph built successfully!")
    logger.info(f"    - Nodes created: {graph_stats['nodes']}")
    logger.info(f"    - Edges created: {graph_stats['edges']}")
    
    # Step 5: Comprehensive Verification
    logger.info(f"\n[5/5] Verifying graph structure and content...")
    
    with db_connection.get_session() as session:
        # Entity type distribution
        type_stats = session.run("""
            MATCH (e:Entity)
            RETURN e.type AS type, count(*) AS count
            ORDER BY count DESC
        """).data()
        
        logger.info(f"\n  Entity type distribution (top 15):")
        for stat in type_stats[:15]:
            logger.info(f"    - {stat['type']}: {stat['count']}")
        
        # GraphRAG specific checks
        logger.info(f"\n  GraphRAG System Verification:")
        
        hoc_phan_count = session.run("""
            MATCH (e:Entity)
            WHERE e.type = 'h·ªçc_ph·∫ßn'
            RETURN count(*) as count
        """).single()['count']
        
        giang_vien_count = session.run("""
            MATCH (e:Entity)
            WHERE e.type = 'gi·∫£ng_vi√™n'
            RETURN count(*) as count
        """).single()['count']
        
        tai_lieu_count = session.run("""
            MATCH (e:Entity)
            WHERE e.type = 't√†i_li·ªáu'
            RETURN count(*) as count
        """).single()['count']
        
        logger.info(f"    ‚úì H·ªçc ph·∫ßn entities: {hoc_phan_count}")
        logger.info(f"    ‚úì Gi·∫£ng vi√™n entities: {giang_vien_count}")
        logger.info(f"    ‚úì T√†i li·ªáu entities: {tai_lieu_count}")
        
        if hoc_phan_count < 5:
            logger.warning("    ‚ö†Ô∏è  Few h·ªçc ph·∫ßn entities - check syllabus data")
        
        # Career Advisor specific checks
        logger.info(f"\n  Career Advisor System Verification:")
        
        career_count = session.run("""
            MATCH (e:Entity)
            WHERE e.type IN ['ngh·ªÅ_nghi·ªáp', 'career', 'v·ªã_tr√≠_c√¥ng_vi·ªác']
            RETURN count(*) as count
        """).single()['count']
        
        major_count = session.run("""
            MATCH (e:Entity)
            WHERE e.type IN ['ng√†nh_h·ªçc', 'ch∆∞∆°ng_tr√¨nh_ƒë√†o_t·∫°o', 'major']
            RETURN count(*) as count
        """).single()['count']
        
        skill_count = session.run("""
            MATCH (e:Entity)
            WHERE e.type IN ['k·ªπ_nƒÉng', 'skill', 'nƒÉng_l·ª±c']
            RETURN count(*) as count
        """).single()['count']
        
        logger.info(f"    ‚úì Ngh·ªÅ nghi·ªáp entities: {career_count}")
        logger.info(f"    ‚úì Ng√†nh h·ªçc entities: {major_count}")
        logger.info(f"    ‚úì K·ªπ nƒÉng entities: {skill_count}")
        
        # Key relationships for Career Advisor
        career_major_rels = session.run("""
            MATCH ()-[r]->()
            WHERE type(r) IN ['ƒê√ÄO_T·∫†O_CHO_NGH·ªÄ', 'TRAINS_FOR', 'Y√äU_C·∫¶U_NG√ÄNH']
            RETURN count(*) as count
        """).single()['count']
        
        skill_rels = session.run("""
            MATCH ()-[r]->()
            WHERE type(r) IN ['Y√äU_C·∫¶U_K·ª∏_NƒÇNG', 'PH√ÅT_TRI·ªÇN_K·ª∏_NƒÇNG', 'C·∫¶N_K·ª∏_NƒÇNG']
            RETURN count(*) as count
        """).single()['count']
        
        logger.info(f"    ‚úì Career ‚Üî Major relationships: {career_major_rels}")
        logger.info(f"    ‚úì Skill-related relationships: {skill_rels}")
        
        if career_count < 5:
            logger.warning("    ‚ö†Ô∏è  Very few career entities!")
            logger.warning("       ‚Üí Career Advisor will have limited functionality")
            logger.warning("       ‚Üí Check 'career description' folder in MinIO")
        
        if career_major_rels < 3:
            logger.warning("    ‚ö†Ô∏è  Few career-major relationships!")
            logger.warning("       ‚Üí Career recommendations may be limited")
        
        # Sample entities for verification
        logger.info(f"\n  Sample Entities (for verification):")
        
        samples = session.run("""
            MATCH (e:Entity)
            WHERE e.type IN ['h·ªçc_ph·∫ßn', 'ngh·ªÅ_nghi·ªáp', 'ng√†nh_h·ªçc']
            RETURN e.type as type, e.name as name
            ORDER BY e.type
            LIMIT 15
        """).data()
        
        current_type = None
        for sample in samples:
            if sample['type'] != current_type:
                current_type = sample['type']
                logger.info(f"\n    {current_type.upper()}:")
            logger.info(f"      ‚Ä¢ {sample['name']}")
        
        # Embeddings status
        logger.info(f"\n  Embeddings Status:")
        embed_count = session.run("""
            MATCH (e:Entity)
            WHERE e.embedding IS NOT NULL
            RETURN count(*) as count
        """).single()['count']
        
        total_nodes = graph_stats['nodes']
        embed_pct = (embed_count / total_nodes * 100) if total_nodes > 0 else 0
        
        logger.info(f"    Entities with embeddings: {embed_count}/{total_nodes} ({embed_pct:.1f}%)")
        
        if embed_pct > 80:
            logger.info(f"    ‚úì Excellent embedding coverage")
        elif embed_pct > 50:
            logger.info(f"    ‚ö†Ô∏è  Good embedding coverage")
        else:
            logger.warning(f"    ‚ö†Ô∏è  Low embedding coverage - may affect search quality")
    
    elapsed = time.time() - start_time
    logger.info(f"\n‚úì Complete graph building finished in {elapsed:.1f}s ({elapsed/60:.1f} minutes)")
    
    db_connection.close()
    
    return {
        'documents': len(documents),
        'doc_types': doc_types,
        'chunks': len(chunks),
        'chunk_types': chunk_types,
        'elements': len(elements),
        'total_entities': total_entities,
        'total_relations': total_relations,
        'graph': graph_stats,
        'entity_types': type_stats,
        'graphrag_stats': {
            'h·ªçc_ph·∫ßn': hoc_phan_count,
            'gi·∫£ng_vi√™n': giang_vien_count,
            't√†i_li·ªáu': tai_lieu_count
        },
        'career_stats': {
            'ngh·ªÅ_nghi·ªáp': career_count,
            'ng√†nh_h·ªçc': major_count,
            'k·ªπ_nƒÉng': skill_count,
            'career_major_links': career_major_rels,
            'skill_links': skill_rels
        },
        'embeddings': {
            'count': embed_count,
            'total': total_nodes,
            'percentage': embed_pct
        },
        'time': elapsed,
        'skipped': False
    }


# =========================================================
# MAIN
# =========================================================

if __name__ == "__main__":
    print("\n" + "=" * 80)
    print("BUILD COMPLETE KNOWLEDGE GRAPH")
    print("=" * 80)
    print("\nThis unified system supports:")
    print("  üîç GraphRAG Query System")
    print("     ‚Üí Answer questions about courses, instructors, materials")
    print("     ‚Üí Example: 'Gi·∫£ng vi√™n n√†o d·∫°y m√¥n Ph√¢n t√≠ch thi·∫øt k·∫ø h·ªá th·ªëng?'")
    print()
    print("  üéì Career Advisor Chatbot")
    print("     ‚Üí Career guidance based on interests and strengths")
    print("     ‚Üí Example: 'Em mu·ªën l√†m k·ªπ s∆∞ ph·∫ßn m·ªÅm, n√™n h·ªçc ng√†nh g√¨?'")
    print()
    print("=" * 80)
    print("\nData Sources (MinIO):")
    print(f"  Endpoint: {MINIO_ENDPOINT}")
    print(f"  Bucket: {MINIO_BUCKET}")
    print(f"  Folders:")
    for folder in MINIO_FOLDERS:
        print(f"    ‚Ä¢ {folder}")
    print()
    print("Configuration:")
    print(f"  Neo4j: {DB_URL}")
    print(f"  Model: {MODEL}")
    print(f"  Chunk size: {CHUNK_SIZE}")
    print(f"  Overlap: {OVERLAP_SIZE}")
    print(f"  Workers: {MAX_WORKERS}")
    print()
    print("Features:")
    print(f"  ‚úì Direct JSON structure parsing")
    print(f"  ‚úì Smart table-paragraph integration")
    print(f"  ‚úì Type-aware entity extraction")
    print(f"  ‚úì Vietnamese text normalization")
    print(f"  ‚úì Embedding-based semantic search")
    print(f"  ‚úì Career-to-major relationship mapping")
    print()
    
    response = input("Continue building complete graph? (yes/no): ")
    if response.lower() != 'yes':
        print("Aborted")
        exit(0)
    
    try:
        results = build_complete_knowledge_graph()
        
        if results is None:
            print("\n‚ö†Ô∏è  Operation cancelled")
            exit(0)
        
        if results.get('skipped'):
            print("\n" + "=" * 80)
            print("üìä USING EXISTING DATA")
            print("=" * 80)
            print(f"Nodes: {results['graph']['nodes']}")
            print(f"Edges: {results['graph']['relationships']}")
            print("=" * 80)
        else:
            # Comprehensive Summary
            print("\n" + "=" * 80)
            print("üìä COMPLETE GRAPH BUILD SUMMARY")
            print("=" * 80)
            
            print(f"\nüìö DATA LOADED:")
            print(f"  Documents: {results['documents']}")
            for doc_type, count in results['doc_types'].items():
                print(f"    ‚Ä¢ {doc_type}: {count}")
            
            print(f"\nüî™ CHUNKING:")
            print(f"  Total chunks: {results['chunks']}")
            for chunk_type, count in results['chunk_types'].items():
                print(f"    ‚Ä¢ {chunk_type}: {count}")
            
            print(f"\nü§ñ EXTRACTION:")
            print(f"  Element sets: {results['elements']}")
            print(f"  Total entities extracted: {results['total_entities']}")
            print(f"  Total relations extracted: {results['total_relations']}")
            
            print(f"\nüï∏Ô∏è  GRAPH:")
            print(f"  Nodes: {results['graph']['nodes']}")
            print(f"  Edges: {results['graph']['edges']}")
            
            print(f"\nüîç GRAPHRAG SYSTEM:")
            grs = results['graphrag_stats']
            print(f"  ‚úì H·ªçc ph·∫ßn: {grs['h·ªçc_ph·∫ßn']}")
            print(f"  ‚úì Gi·∫£ng vi√™n: {grs['gi·∫£ng_vi√™n']}")
            print(f"  ‚úì T√†i li·ªáu: {grs['t√†i_li·ªáu']}")
            
            print(f"\nüéì CAREER ADVISOR SYSTEM:")
            cs = results['career_stats']
            print(f"  ‚úì Ngh·ªÅ nghi·ªáp: {cs['ngh·ªÅ_nghi·ªáp']}")
            print(f"  ‚úì Ng√†nh h·ªçc: {cs['ng√†nh_h·ªçc']}")
            print(f"  ‚úì K·ªπ nƒÉng: {cs['k·ªπ_nƒÉng']}")
            print(f"  ‚úì Career ‚Üî Major links: {cs['career_major_links']}")
            print(f"  ‚úì Skill links: {cs['skill_links']}")
            
            print(f"\nüîÆ EMBEDDINGS:")
            emb = results['embeddings']
            print(f"  Coverage: {emb['count']}/{emb['total']} ({emb['percentage']:.1f}%)")
            
            print(f"\n‚è±Ô∏è  TIME:")
            print(f"  Total: {results['time']:.1f}s ({results['time']/60:.1f} minutes)")
            
            print("\n" + "=" * 80)
            
            # Next Steps
            print("\nüí° NEXT STEPS:")
            print("\n  For GraphRAG Query System:")
            print("    1. python debug_graph_v3.py")
            print("       ‚Üí Verify h·ªçc ph·∫ßn, gi·∫£ng vi√™n data")
            print()
            print("    2. python query_cli_v3.py")
            print("       ‚Üí Try: 'Gi·∫£ng vi√™n n√†o d·∫°y PTTKHT?'")
            print("       ‚Üí Try: 'T√†i li·ªáu tham kh·∫£o cho m√¥n n√†y?'")
            
            print("\n  For Career Advisor:")
            print("    1. python career_advisor_cli.py")
            print("       ‚Üí Function 1: Career ‚Üí Major advisory")
            print("       ‚Üí Function 2: Subject ‚Üí Career advisory")
            print()
            print("    2. python career_advisor_cli.py examples")
            print("       ‚Üí See usage examples")
            
            print("\n" + "=" * 80)
            
            # Warnings & Recommendations
            if cs['ngh·ªÅ_nghi·ªáp'] < 10:
                print("\n‚ö†Ô∏è  WARNING: Few career entities detected!")
                print("   ‚Üí Career Advisor functionality will be limited")
                print("   ‚Üí Action: Check 'career description' folder in MinIO")
                print("   ‚Üí Run: python check_minio_docs.py")
            
            if grs['h·ªçc_ph·∫ßn'] < 10:
                print("\n‚ö†Ô∏è  WARNING: Few h·ªçc ph·∫ßn entities detected!")
                print("   ‚Üí GraphRAG query system will have limited data")
                print("   ‚Üí Action: Check 'syllabus' folder in MinIO")
            
            if emb['percentage'] < 50:
                print("\n‚ö†Ô∏è  WARNING: Low embedding coverage!")
                print("   ‚Üí Semantic search quality may be affected")
                print("   ‚Üí This might be due to API rate limits")
                print("   ‚Üí Re-run build to generate remaining embeddings")
            
            if cs['ngh·ªÅ_nghi·ªáp'] >= 10 and grs['h·ªçc_ph·∫ßn'] >= 10 and emb['percentage'] > 80:
                print("\n‚úÖ EXCELLENT! Graph is ready for both systems!")
                print("   ‚Üí GraphRAG: Ready for course queries")
                print("   ‚Üí Career Advisor: Ready for career guidance")
        
    except Exception as e:
        logger.error(f"Error: {e}", exc_info=True)
        print(f"\n‚ùå Error occurred: {e}")
        print("Check logs/ directory for details")
        raise