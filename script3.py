"""
Script 3: Knowledge Graph Q&A Chatbot
Fixes v2:

  - Intent detection: phÃ¢n loáº¡i thá»±c thá»ƒ Ä‘á» cáº­p / thá»±c thá»ƒ Ä‘Æ°á»£c há»i
  - Relationship constraints per query type: rÃ ng buá»™c Ä‘Æ°á»ng truy xuáº¥t theo loáº¡i cÃ¢u há»i
  - Negation handling: nháº­n diá»‡n "ko / k / khÃ´ng / cháº³ng / kÃ©m / chÆ°a giá»i" â†’ lá»c thá»±c thá»ƒ phá»§ Ä‘á»‹nh
  - Prompt AI tráº£ lá»i sÃ¡t trá»ng tÃ¢m, khÃ´ng thÃªm thÃ´ng tin ngoÃ i lá»
"""

import os
import json
import uuid
import datetime
from pathlib import Path
from collections import deque
from neo4j import GraphDatabase
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NEO4J_URI      = os.getenv("DB_URL")
NEO4J_USERNAME = os.getenv("DB_USER")
NEO4J_PASSWORD = os.getenv("DB_PASSWORD")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL   = os.getenv("OPENAI_MODEL")

MAX_HOPS    = int(os.getenv("MAX_HOPS", "3"))
TOP_K       = int(os.getenv("TOP_K", "15"))
LOG_DIR     = Path("./qa_logs")
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Tá»« Ä‘á»“ng nghÄ©a phá»§ Ä‘á»‹nh â€” nháº­n diá»‡n cÃ¢u há»i cÃ³ tá»« phá»§ Ä‘á»‹nh / "khÃ´ng giá»i"
NEGATION_SYNONYMS = {
    "ko", "k", "khÃ´ng", "cháº³ng", "cháº£", "kÃ©m", "chÆ°a giá»i",
    "khÃ´ng giá»i", "ko giá»i", "k giá»i", "yáº¿u", "dá»Ÿ",
    "khÃ´ng thÃ­ch", "ko thÃ­ch", "k thÃ­ch", "chÃ¡n",
    "khÃ´ng muá»‘n", "ko muá»‘n", "khÃ´ng cÃ³", "ko cÃ³",
    "khÃ´ng biáº¿t", "ko biáº¿t", "chÆ°a biáº¿t",
}

SCHEMA_DESC = """
Nodes: MAJOR{name,code,community_id,pagerank}, SUBJECT{name,code,community_id,pagerank},
       SKILL{name,community_id,pagerank}, CAREER{name,community_id,pagerank},
       TEACHER{name,community_id}, DOCUMENT{name,docid,doctype}
Relationships:
  (MAJOR)-[:OFFERS]->(SUBJECT)
  (TEACHER)-[:TEACH]->(SUBJECT)
  (SUBJECT)-[:PROVIDES]->(SKILL)
  (CAREER)-[:REQUIRES]->(SKILL)
  (SUBJECT)-[:PREREQUISITE_FOR]->(SUBJECT)
  (MAJOR)-[:LEADS_TO]->(CAREER)
  (*)-[:MENTIONED_IN]->(DOCUMENT)
All name values are UPPERCASE Vietnamese.
"""

# â”€â”€ RÃ ng buá»™c quan há»‡ theo loáº¡i cÃ¢u há»i â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Key: (thá»±c thá»ƒ Ä‘á» cáº­p, thá»±c thá»ƒ Ä‘Æ°á»£c há»i)
RELATIONSHIP_CONSTRAINTS = {
    # Äá» cáº­p MAJOR â†’ há»i CAREER
    ("MAJOR", "CAREER"): (
        "ÄÆ°á»ng truy xuáº¥t: MAJOR -[:LEADS_TO]-> CAREER.\n"
        "Chá»‰ liá»‡t kÃª cÃ¡c nghá» nghiá»‡p (CAREER) mÃ  ngÃ nh (MAJOR) dáº«n Ä‘áº¿n.\n"
        "KHÃ”NG Ä‘á» cáº­p SUBJECT (mÃ´n há»c) trá»« khi Ä‘Æ°á»£c há»i thÃªm."
    ),
    # Äá» cáº­p CAREER â†’ há»i SKILL
    ("CAREER", "SKILL"): (
        "ÄÆ°á»ng truy xuáº¥t: CAREER -[:REQUIRES]-> SKILL vÃ  SUBJECT -[:PROVIDES]-> SKILL.\n"
        "Tráº£ lá»i: ká»¹ nÄƒng cáº§n thiáº¿t cho nghá» Ä‘Ã³ + mÃ´n há»c cung cáº¥p ká»¹ nÄƒng tÆ°Æ¡ng á»©ng.\n"
        "KÃ¨m mÃ£ mÃ´n há»c náº¿u cÃ³."
    ),
    # Äá» cáº­p MAJOR â†’ há»i SKILL
    ("MAJOR", "SKILL"): (
        "ÄÆ°á»ng truy xuáº¥t: MAJOR -[:OFFERS]-> SUBJECT -[:PROVIDES]-> SKILL.\n"
        "Tráº£ lá»i: ká»¹ nÄƒng Ä‘áº¡t Ä‘Æ°á»£c tá»« cÃ¡c mÃ´n há»c trong chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o.\n"
        "KÃ¨m tÃªn mÃ´n há»c (mÃ£ mÃ´n) cung cáº¥p ká»¹ nÄƒng Ä‘Ã³."
    ),
    # Äá» cáº­p SKILL â†’ há»i MAJOR
    ("SKILL", "MAJOR"): (
        "ÄÆ°á»ng truy xuáº¥t: SKILL <-[:PROVIDES]- SUBJECT <-[:OFFERS]- MAJOR.\n"
        "Tráº£ lá»i: ngÃ nh há»c (MAJOR) cÃ³ mÃ´n há»c cung cáº¥p ká»¹ nÄƒng Ä‘Ã³.\n"
        "KÃ¨m mÃ£ ngÃ nh, tÃªn mÃ´n trung gian."
    ),
    # Äá» cáº­p CAREER â†’ há»i SUBJECT (mÃ´n há»c)
    ("CAREER", "SUBJECT"): (
        "ÄÆ°á»ng truy xuáº¥t: CAREER -[:REQUIRES]-> SKILL <-[:PROVIDES]- SUBJECT.\n"
        "Tráº£ lá»i: cÃ¡c mÃ´n há»c cung cáº¥p ká»¹ nÄƒng mÃ  nghá» Ä‘Ã³ yÃªu cáº§u.\n"
        "KÃ¨m mÃ£ mÃ´n há»c vÃ  ká»¹ nÄƒng tÆ°Æ¡ng á»©ng."
    ),
    # Äá» cáº­p MAJOR â†’ há»i SUBJECT (mÃ´n há»c)
    ("MAJOR", "SUBJECT"): (
        "ÄÆ°á»ng truy xuáº¥t: MAJOR -[:OFFERS]-> SUBJECT.\n"
        "Tráº£ lá»i: cÃ¡c mÃ´n há»c thuá»™c chÆ°Æ¡ng trÃ¬nh ngÃ nh Ä‘Ã³, kÃ¨m mÃ£ mÃ´n vÃ  ká»¹ nÄƒng cung cáº¥p (SKILL)."
    ),
    # Äá» cáº­p SKILL â†’ há»i CAREER
    ("SKILL", "CAREER"): (
        "ÄÆ°á»ng truy xuáº¥t: SKILL <-[:REQUIRES]- CAREER.\n"
        "Tráº£ lá»i: danh sÃ¡ch nghá» nghiá»‡p yÃªu cáº§u ká»¹ nÄƒng Ä‘Ã³."
    ),
    # Äá» cáº­p CAREER â†’ há»i MAJOR
    ("CAREER", "MAJOR"): (
        "ÄÆ°á»ng truy xuáº¥t: MAJOR -[:LEADS_TO]-> CAREER.\n"
        "Tráº£ lá»i: ngÃ nh há»c (MAJOR) dáº«n Ä‘áº¿n nghá» Ä‘Ã³, kÃ¨m mÃ£ ngÃ nh."
    ),
    # Äá» cáº­p SUBJECT â†’ há»i SKILL
    ("SUBJECT", "SKILL"): (
        "ÄÆ°á»ng truy xuáº¥t: SUBJECT -[:PROVIDES]-> SKILL.\n"
        "Tráº£ lá»i: ká»¹ nÄƒng Ä‘áº¡t Ä‘Æ°á»£c sau khi há»c mÃ´n Ä‘Ã³."
    ),
    # Äá» cáº­p SKILL â†’ há»i SUBJECT
    ("SKILL", "SUBJECT"): (
        "ÄÆ°á»ng truy xuáº¥t: SKILL <-[:PROVIDES]- SUBJECT.\n"
        "Tráº£ lá»i: mÃ´n há»c (kÃ¨m mÃ£ mÃ´n) cung cáº¥p ká»¹ nÄƒng Ä‘Ã³, vÃ  ngÃ nh nÃ o chá»©a mÃ´n Ä‘Ã³."
    ),
    # Äá» cáº­p MAJOR â†’ so sÃ¡nh nhiá»u ngÃ nh
    ("MAJOR", "MAJOR"): (
        "ÄÃ¢y lÃ  cÃ¢u so sÃ¡nh giá»¯a cÃ¡c ngÃ nh.\n"
        "Truy xuáº¥t: MAJOR -[:LEADS_TO]-> CAREER vÃ  MAJOR -[:OFFERS]-> SUBJECT.\n"
        "Tráº£ lá»i: so sÃ¡nh cÆ¡ há»™i nghá» nghiá»‡p vÃ  mÃ´n há»c Ä‘áº·c trÆ°ng cá»§a tá»«ng ngÃ nh.\n"
        "KÃ¨m mÃ£ ngÃ nh, mÃ£ mÃ´n há»c náº¿u cÃ³. TrÃ­ch dáº«n nguá»“n tÃ i liá»‡u (DOCUMENT) náº¿u cÃ³."
    ),
    # Äá» cáº­p MAJOR/CAREER â†’ há»i CAREER/MAJOR (tá»•ng quÃ¡t)
    ("MAJOR", "MAJOR_CAREER"): (
        "ÄÆ°á»ng truy xuáº¥t: MAJOR -[:LEADS_TO]-> CAREER vÃ  MAJOR -[:OFFERS]-> SUBJECT -[:PROVIDES]-> SKILL.\n"
        "Tráº£ lá»i nghá» nghiá»‡p + ká»¹ nÄƒng Ä‘áº·c trÆ°ng + mÃ´n há»c trong ngÃ nh Ä‘Ã³."
    ),
}

# â”€â”€ Prompt há»‡ thá»‘ng chÃ­nh cho generate_answer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ANSWER_SYSTEM_BASE = """Báº¡n lÃ  trá»£ lÃ½ tÆ° váº¥n há»c thuáº­t cho Äáº¡i há»c Kinh táº¿ Quá»‘c dÃ¢n (NEU).
Tá»•ng há»£p cÃ¢u tráº£ lá»i rÃµ rÃ ng, tá»± nhiÃªn báº±ng tiáº¿ng Viá»‡t tá»« káº¿t quáº£ Knowledge Graph Ä‘Ã£ xáº¿p háº¡ng.

{schema}

QUY Táº®C QUAN TRá»ŒNG:
1. Tráº£ lá»i ÄÃšNG TRá»ŒNG TÃ‚M cÃ¢u há»i. KhÃ´ng thÃªm thÃ´ng tin khÃ´ng Ä‘Æ°á»£c há»i Ä‘áº¿n.
2. KhÃ´ng dÃ¹ng cÃ¢u "ngoÃ i ra..." Ä‘á»ƒ má»Ÿ rá»™ng ngoÃ i pháº¡m vi cÃ¢u há»i.
3. Náº¿u dá»¯ liá»‡u khÃ´ng Ä‘á»§ Ä‘á»ƒ tráº£ lá»i â†’ nÃ³i rÃµ "Dá»¯ liá»‡u hiá»‡n táº¡i chÆ°a Ä‘á»§ Ä‘á»ƒ tÆ° váº¥n vá» [chá»§ Ä‘á»], báº¡n cÃ³ thá»ƒ liÃªn há»‡ phÃ²ng Ä‘Ã o táº¡o Ä‘á»ƒ biáº¿t thÃªm."
4. KHÃ”NG bá»‹a thÃ´ng tin khÃ´ng cÃ³ trong Knowledge Graph.
5. LuÃ´n kÃ¨m mÃ£ ngÃ nh (MAJOR.code) vÃ  mÃ£ mÃ´n há»c (SUBJECT.code) khi cÃ³ trong dá»¯ liá»‡u.
6. Khi ngÆ°á»i dÃ¹ng Ä‘á» cáº­p thá»±c thá»ƒ mÃ  há» KHÃ”NG giá»i / khÃ´ng thÃ­ch â†’ loáº¡i bá» thá»±c thá»ƒ Ä‘Ã³ khá»i cÃ¢u tráº£ lá»i.
7. NgÃ´n ngá»¯ tá»± nhiÃªn, thÃ¢n thiá»‡n â€” KHÃ”NG mÃ¡y mÃ³c, lÃ½ thuyáº¿t.

RÃ€NG BUá»˜C THEO LOáº I CÃ‚U Há»I:
{constraint}
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BÆ¯á»šC 0: SETUP â€” Cháº¡y Community Detection + PageRank (offline, 1 láº§n)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def setup_graph_algorithms(driver):
    """
    Global Community Detection (Louvain) + PageRank
    Cháº¡y trÃªn toÃ n bá»™ graph (khÃ´ng chia theo label).
    PhÃ¹ há»£p cho GraphRAG reasoning Ä‘a thá»±c thá»ƒ.
    """

    try:
        import networkx as nx
        from networkx.algorithms.community import louvain_communities
    except ImportError:
        print("CÃ i networkx: pip install networkx")
        return

    print("\n[Setup] Pull graph tá»« Neo4j â†’ tÃ­nh Global Louvain + PageRank...")

    G = nx.Graph()

    # â”€â”€â”€ 1. Pull nodes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with driver.session() as session:

        nodes = session.run("""
            MATCH (n)
            WHERE n:MAJOR OR n:SUBJECT OR n:SKILL OR n:CAREER OR n:TEACHER
            RETURN n.name AS name
        """).data()

        for row in nodes:
            if row["name"]:
                G.add_node(row["name"])

        # â”€â”€â”€ 2. Pull relationships â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        rels = session.run("""
            MATCH (a)-[r]->(b)
            WHERE (a:MAJOR OR a:SUBJECT OR a:SKILL OR a:CAREER OR a:TEACHER)
              AND (b:MAJOR OR b:SUBJECT OR b:SKILL OR b:CAREER OR b:TEACHER)
              AND a.name IS NOT NULL AND b.name IS NOT NULL
            RETURN a.name AS src, b.name AS tgt
        """).data()

        for row in rels:
            G.add_edge(row["src"], row["tgt"])

    print(f"Graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges")

    # â”€â”€â”€ 3. Global Louvain â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("Cháº¡y Global Louvain community detection...")
    communities = louvain_communities(G, seed=42)

    node_community = {}
    for cid, community in enumerate(communities):
        for node in community:
            node_community[node] = cid

    print(f"TÃ¬m tháº¥y {len(communities)} communities")

    # â”€â”€â”€ 4. PageRank â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("Cháº¡y PageRank...")
    pagerank = nx.pagerank(G, alpha=0.85, max_iter=100)

    # â”€â”€â”€ 5. Ghi láº¡i Neo4j â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("Ghi community_id + pagerank lÃªn Neo4j...")

    with driver.session() as session:
        BATCH_SIZE = 500
        items = list(node_community.items())

        for i in range(0, len(items), BATCH_SIZE):
            batch = [
                {
                    "name": name,
                    "cid": cid,
                    "pr": round(pagerank.get(name, 0.0), 8)
                }
                for name, cid in items[i:i+BATCH_SIZE]
            ]

            session.run("""
                UNWIND $batch AS row
                MATCH (n) WHERE n.name = row.name
                SET n.community_id = row.cid,
                    n.pagerank      = row.pr
            """, batch=batch)

    print(f"ÄÃ£ ghi {len(node_community)} nodes")
    print("[Setup] Xong.\n")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Má»šI: EXTRACT QUERY INTENT â€” PhÃ¢n loáº¡i Ã½ Ä‘á»‹nh cÃ¢u há»i
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extract_query_intent(ai_client: OpenAI, question: str) -> dict:
    """
    TrÃ­ch xuáº¥t:
    - keywords: tá»« khoÃ¡ tÃ¬m kiáº¿m thá»±c thá»ƒ trong KG
    - mentioned_labels: loáº¡i thá»±c thá»ƒ Ä‘Æ°á»£c Ä‘á» cáº­p trong cÃ¢u há»i
    - asked_label: loáº¡i thá»±c thá»ƒ ngÆ°á»i dÃ¹ng muá»‘n biáº¿t
    - negated_keywords: tá»« khoÃ¡ ngÆ°á»i dÃ¹ng phá»§ Ä‘á»‹nh (khÃ´ng giá»i, khÃ´ng thÃ­ch, ...)
    - is_comparison: cÃ¢u há»i so sÃ¡nh
    """

    system_msg = (
        "Báº¡n phÃ¢n tÃ­ch cÃ¢u há»i tÆ° váº¥n há»c thuáº­t vÃ  tráº£ vá» JSON.\n"
        "Schema Knowledge Graph:\n"
        "  Node labels: MAJOR (ngÃ nh há»c), SUBJECT (mÃ´n há»c), SKILL (ká»¹ nÄƒng), "
        "CAREER (nghá» nghiá»‡p / vá»‹ trÃ­ viá»‡c lÃ m), TEACHER (giáº£ng viÃªn)\n\n"
        "Tá»« Ä‘á»“ng nghÄ©a phá»§ Ä‘á»‹nh: ko, k, khÃ´ng, cháº³ng, kÃ©m, yáº¿u, dá»Ÿ, chÆ°a giá»i, "
        "khÃ´ng giá»i, khÃ´ng thÃ­ch, khÃ´ng muá»‘n, khÃ´ng biáº¿t\n\n"
        "PHÃ‚N BIá»†T QUAN TRá»ŒNG:\n"
        "  - Há»i 'mÃ´n há»c / mÃ´n nÃ o / há»c mÃ´n gÃ¬' â†’ asked_label: 'SUBJECT'\n"
        "  - Há»i 'ngÃ nh nÃ o / há»c ngÃ nh gÃ¬ / chuyÃªn ngÃ nh' â†’ asked_label: 'MAJOR'\n"
        "QUAN TRá»ŒNG - Chuáº©n hÃ³a keyword vá» tiáº¿ng Viá»‡t theo graph:\n"
        "  data analyst â†’ chuyÃªn viÃªn phÃ¢n tÃ­ch dá»¯ liá»‡u\n"
        "  software engineer / developer â†’ láº­p trÃ¬nh viÃªn, ká»¹ sÆ° pháº§n má»m\n"
        "  tester / QA â†’ kiá»ƒm thá»­\n"
        "  IT / information technology â†’ cÃ´ng nghá»‡ thÃ´ng tin\n"
        "  AI / machine learning â†’ trÃ­ tuá»‡ nhÃ¢n táº¡o, há»c mÃ¡y\n"
        "  Náº¿u khÃ´ng biáº¿t tÃªn tiáº¿ng Viá»‡t â†’ giá»¯ nguyÃªn tiáº¿ng Anh\n\n"
        "Tráº£ vá» JSON vá»›i Ä‘Ãºng cÃ¡c trÆ°á»ng sau:\n"
        "{\n"
        '  "keywords": ["tá»« khoÃ¡ thá»±c thá»ƒ Ä‘á»ƒ tÃ¬m trong KG"],\n'
        '  "mentioned_labels": ["MAJOR|SUBJECT|SKILL|CAREER|TEACHER"],\n'
        '  "asked_label": "MAJOR|SUBJECT|SKILL|CAREER|TEACHER|UNKNOWN",\n'
        '  "negated_keywords": ["thá»±c thá»ƒ / ká»¹ nÄƒng / mÃ´n bá»‹ phá»§ Ä‘á»‹nh"],\n'
        '  "is_comparison": true\n'
        "}\n\n"
        "VÃ­ dá»¥:\n"
        '  CÃ¢u: "Giá»i giao tiáº¿p thÃ¬ há»c ngÃ nh nÃ o?" â†’ mentioned_labels: ["SKILL"], asked_label: "MAJOR"\n'
        '  CÃ¢u: "NgÃ nh CNTT cÃ³ nhá»¯ng nghá» gÃ¬?" â†’ mentioned_labels: ["MAJOR"], asked_label: "CAREER"\n'
        '  CÃ¢u: "Ko giá»i toÃ¡n thÃ¬ theo nghá» láº­p trÃ¬nh viÃªn Ä‘Æ°á»£c khÃ´ng?" '
        'â†’ negated_keywords: ["toÃ¡n"], mentioned_labels: ["CAREER"]\n'
        '  CÃ¢u: "CNTT hay KTPM phÃ¹ há»£p hÆ¡n?" â†’ is_comparison: true, mentioned_labels: ["MAJOR"]\n'
        '  CÃ¢u: "Há»c mÃ´n gÃ¬ Ä‘á»ƒ lÃ m láº­p trÃ¬nh viÃªn?" â†’ mentioned_labels: ["CAREER"], asked_label: "SUBJECT"\n'
        '  CÃ¢u: "MÃ´n nÃ o giÃºp tÃ´i trá»Ÿ thÃ nh data analyst?" â†’ mentioned_labels: ["CAREER"], asked_label: "SUBJECT"\n'
        '  CÃ¢u: "Cáº§n há»c nhá»¯ng mÃ´n gÃ¬ cho nghá» káº¿ toÃ¡n?" â†’ mentioned_labels: ["CAREER"], asked_label: "SUBJECT"\n'
    )

    response = ai_client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[
            {"role": "system", "content": system_msg},
            {"role": "user",   "content": f"Phan tich cau hoi sau va tra ve json: {question}"},
        ],
        temperature=0,
        response_format={"type": "json_object"},
    )
    parsed = json.loads(response.choices[0].message.content)
    return {
        "keywords":        parsed.get("keywords", []),
        "mentioned_labels": parsed.get("mentioned_labels", []),
        "asked_label":     parsed.get("asked_label", "UNKNOWN"),
        "negated_keywords": parsed.get("negated_keywords", []),
        "is_comparison":   parsed.get("is_comparison", False),
    }


def detect_negation_in_question(question: str) -> bool:
    """Kiá»ƒm tra nhanh cÃ¢u há»i cÃ³ chá»©a tá»« phá»§ Ä‘á»‹nh khÃ´ng."""
    q_lower = question.lower()
    for neg in NEGATION_SYNONYMS:
        if neg in q_lower:
            return True
    return False


def get_relationship_constraint(intent: dict) -> str:
    """Láº¥y rÃ ng buá»™c quan há»‡ dá»±a trÃªn intent."""
    mentioned = intent.get("mentioned_labels", [])
    asked     = intent.get("asked_label", "UNKNOWN")
    is_comp   = intent.get("is_comparison", False)

    if is_comp and "MAJOR" in mentioned:
        return RELATIONSHIP_CONSTRAINTS.get(("MAJOR", "MAJOR"), "")

    # Láº¥y label Ä‘á» cáº­p Ä‘áº§u tiÃªn
    first_mentioned = mentioned[0] if mentioned else None

    if first_mentioned and asked and asked != "UNKNOWN":
        key = (first_mentioned, asked)
        if key in RELATIONSHIP_CONSTRAINTS:
            return RELATIONSHIP_CONSTRAINTS[key]

    # Thá»­ tá»• há»£p khÃ¡c
    for m in mentioned:
        key = (m, asked)
        if key in RELATIONSHIP_CONSTRAINTS:
            return RELATIONSHIP_CONSTRAINTS[key]

    return "Tráº£ lá»i theo Ä‘Ãºng cÃ¢u há»i, chá»‰ dÃ¹ng dá»¯ liá»‡u cÃ³ trong Knowledge Graph."


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BÆ¯á»šC 1: COMMUNITY DETECTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def find_relevant_communities(driver, keywords: list[str]) -> list[int]:
    if not keywords:
        return []
    with driver.session() as session:
        community_ids = set()
        for kw in keywords:
            result = session.run("""
                MATCH (n)
                WHERE (n:MAJOR OR n:SUBJECT OR n:SKILL OR n:CAREER OR n:TEACHER)
                  AND toLower(n.name) CONTAINS toLower($kw)
                  AND n.community_id IS NOT NULL
                RETURN DISTINCT n.community_id AS cid
                LIMIT 5
            """, kw=kw)
            for rec in result:
                community_ids.add(rec["cid"])
    return list(community_ids)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BÆ¯á»šC 2: MULTI-HOP TRAVERSAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _add_node_and_paths(rec, all_nodes, all_paths):
    """Helper: parse 1 record tá»« traversal query vÃ o all_nodes / all_paths."""
    node_info = {
        "name":         rec["name"],
        "label":        rec["label"],
        "code":         rec["code"],
        "pagerank":     rec["pagerank"],
        "community_id": rec["community_id"],
        "hops":         rec["hops"],
    }
    all_nodes.append(node_info)
    node_names = rec["node_names"]
    rel_types  = rec["rel_types"]
    for i, rel in enumerate(rel_types):
        all_paths.append({
            "from":     node_names[i]   if i < len(node_names) else "",
            "to":       node_names[i+1] if i+1 < len(node_names) else "",
            "relation": rel,
            "hop":      i + 1,
        })


# Báº£ng cÃ¡c targeted query theo intent (mentioned_label, asked_label)
# DÃ¹ng khi BFS thÃ´ng thÆ°á»ng bá»‹ cháº·n bá»Ÿi community filter
TARGETED_QUERIES: dict[tuple[str, str], str] = {
    ("MAJOR", "CAREER"): """
        MATCH (start:MAJOR)-[:LEADS_TO]->(n:CAREER)
        WHERE toLower(start.name) CONTAINS toLower($kw)
        RETURN n.name AS name, labels(n)[0] AS label, n.code AS code,
               n.pagerank AS pagerank, n.community_id AS community_id,
               ['LEADS_TO'] AS rel_types, [start.name, n.name] AS node_names, 1 AS hops
        LIMIT 30
    """,
    ("CAREER", "SKILL"): """
        MATCH (start:CAREER)-[:REQUIRES]->(n:SKILL)
        WHERE toLower(start.name) CONTAINS toLower($kw)
           OR toLower(start.name) CONTAINS 'phÃ¢n tÃ­ch'
           OR toLower(start.name) CONTAINS 'analyst'
        RETURN n.name AS name, labels(n)[0] AS label, n.code AS code,
               n.pagerank AS pagerank, n.community_id AS community_id,
               ['REQUIRES'] AS rel_types, [start.name, n.name] AS node_names, 1 AS hops
        LIMIT 30
    """,
    ("MAJOR", "SKILL"): """
        MATCH (start:MAJOR)-[:OFFERS]->(sub:SUBJECT)-[:PROVIDES]->(n:SKILL)
        WHERE toLower(start.name) CONTAINS toLower($kw)
        RETURN n.name AS name, labels(n)[0] AS label, n.code AS code,
               n.pagerank AS pagerank, n.community_id AS community_id,
               ['OFFERS','PROVIDES'] AS rel_types, [start.name, sub.name, n.name] AS node_names, 2 AS hops
        LIMIT 30
    """,
    ("SKILL", "MAJOR"): """
        MATCH (n:MAJOR)-[:OFFERS]->(sub:SUBJECT)-[:PROVIDES]->(start:SKILL)
        WHERE toLower(start.name) CONTAINS toLower($kw)
        RETURN n.name AS name, labels(n)[0] AS label, n.code AS code,
               n.pagerank AS pagerank, n.community_id AS community_id,
               ['OFFERS','PROVIDES'] AS rel_types, [n.name, sub.name, start.name] AS node_names, 2 AS hops
        LIMIT 30
    """,
    ("SKILL", "CAREER"): """
        MATCH (n:CAREER)-[:REQUIRES]->(start:SKILL)
        WHERE toLower(start.name) CONTAINS toLower($kw)
        RETURN n.name AS name, labels(n)[0] AS label, n.code AS code,
               n.pagerank AS pagerank, n.community_id AS community_id,
               ['REQUIRES'] AS rel_types, [n.name, start.name] AS node_names, 1 AS hops
        LIMIT 30
    """,
    ("CAREER", "SUBJECT"): """
        MATCH (start:CAREER)-[:REQUIRES]->(sk:SKILL)<-[:PROVIDES]-(n:SUBJECT)
        WHERE toLower(start.name) CONTAINS toLower($kw)
        RETURN n.name AS name, labels(n)[0] AS label, n.code AS code,
               n.pagerank AS pagerank, n.community_id AS community_id,
               ['REQUIRES','PROVIDES'] AS rel_types, [start.name, sk.name, n.name] AS node_names, 2 AS hops
        LIMIT 30
    """,
    ("MAJOR", "SUBJECT"): """
        MATCH (start:MAJOR)-[:OFFERS]->(n:SUBJECT)
        WHERE toLower(start.name) CONTAINS toLower($kw)
        RETURN n.name AS name, labels(n)[0] AS label, n.code AS code,
               n.pagerank AS pagerank, n.community_id AS community_id,
               ['OFFERS'] AS rel_types, [start.name, n.name] AS node_names, 1 AS hops
        LIMIT 30
    """,
    ("SKILL", "SUBJECT"): """
        MATCH (n:SUBJECT)-[:PROVIDES]->(start:SKILL)
        WHERE toLower(start.name) CONTAINS toLower($kw)
        RETURN n.name AS name, labels(n)[0] AS label, n.code AS code,
               n.pagerank AS pagerank, n.community_id AS community_id,
               ['PROVIDES'] AS rel_types, [n.name, start.name] AS node_names, 1 AS hops
        LIMIT 30
    """,
    ("SUBJECT", "SKILL"): """
        MATCH (start:SUBJECT)-[:PROVIDES]->(n:SKILL)
        WHERE toLower(start.name) CONTAINS toLower($kw)
        RETURN n.name AS name, labels(n)[0] AS label, n.code AS code,
               n.pagerank AS pagerank, n.community_id AS community_id,
               ['PROVIDES'] AS rel_types, [start.name, n.name] AS node_names, 1 AS hops
        LIMIT 30
    """,
    ("CAREER", "MAJOR"): """
        MATCH (n:MAJOR)-[:LEADS_TO]->(start:CAREER)
        WHERE toLower(start.name) CONTAINS toLower($kw)
        RETURN n.name AS name, labels(n)[0] AS label, n.code AS code,
               n.pagerank AS pagerank, n.community_id AS community_id,
               ['LEADS_TO'] AS rel_types, [n.name, start.name] AS node_names, 1 AS hops
        LIMIT 30
    """,
}


def multihop_traversal(driver, keywords: list[str],
                       community_ids: list[int],
                       max_hops: int = MAX_HOPS,
                       intent: dict | None = None) -> tuple[list[dict], list[dict]]:
    all_nodes  = []
    all_paths  = []
    seen_names = set()

    mentioned_labels = (intent or {}).get("mentioned_labels", [])
    asked_label      = (intent or {}).get("asked_label", "UNKNOWN")
    first_mentioned  = mentioned_labels[0] if mentioned_labels else None

    # â”€â”€ Phase 1: Targeted query theo intent (khÃ´ng bá»‹ cháº·n bá»Ÿi community) â”€â”€â”€â”€
    targeted_key = (first_mentioned, asked_label) if first_mentioned else None
    targeted_cypher = TARGETED_QUERIES.get(targeted_key) if targeted_key else None

    if targeted_cypher:
        with driver.session() as session:
            for kw in keywords:
                try:
                    results = session.run(targeted_cypher, kw=kw)
                    for rec in results:
                        _add_node_and_paths(rec, all_nodes, all_paths)
                    if all_nodes:
                        print(f"  [targeted] ({targeted_key}) â†’ {len(all_nodes)} nodes via direct path")
                except Exception as e:
                    print(f"  [targeted] WARNING: {e}")

    # â”€â”€ Phase 2: BFS thÃ´ng thÆ°á»ng (community-filtered) Ä‘á»ƒ láº¥y context â”€â”€â”€â”€â”€â”€â”€â”€
    with driver.session() as session:
        for kw in keywords:
            seed_query = """
                MATCH (seed)
                WHERE (seed:MAJOR OR seed:SUBJECT OR seed:SKILL OR seed:CAREER OR seed:TEACHER)
                  AND toLower(seed.name) CONTAINS toLower($kw)
                RETURN seed
                LIMIT 3
            """
            seeds = [rec["seed"] for rec in session.run(seed_query, kw=kw)]

            for seed in seeds:
                seed_name = seed.get("name", "")
                if seed_name in seen_names:
                    continue
                seen_names.add(seed_name)

                # Community filter KHÃ”NG Ã¡p dá»¥ng cho asked_label
                # Ä‘á»ƒ trÃ¡nh cháº·n cÃ¡c node Ä‘Ã­ch quan trá»ng
                community_filter = ""
                params: dict = {"seed_name": seed_name, "max_hops": max_hops}

                if community_ids and asked_label not in ("UNKNOWN", None):
                    community_filter = (
                        f"AND (n.community_id IN $cids "
                        f"OR n.community_id IS NULL "
                        f"OR labels(n)[0] = '{asked_label}')"
                    )
                    params["cids"] = community_ids
                elif community_ids:
                    community_filter = "AND (n.community_id IN $cids OR n.community_id IS NULL)"
                    params["cids"] = community_ids

                traversal_query = f"""
                    MATCH path = (start)-[*1..{max_hops}]-(n)
                    WHERE start.name = $seed_name
                      AND (n:MAJOR OR n:SUBJECT OR n:SKILL OR n:CAREER OR n:TEACHER)
                      {community_filter}
                    WITH n, path,
                         [r IN relationships(path) | type(r)] AS rel_types,
                         [x IN nodes(path) | x.name]          AS node_names
                    RETURN DISTINCT
                        n.name         AS name,
                        labels(n)[0]   AS label,
                        n.code         AS code,
                        n.pagerank     AS pagerank,
                        n.community_id AS community_id,
                        rel_types,
                        node_names,
                        length(path)   AS hops
                    ORDER BY hops ASC
                    LIMIT 50
                """
                results = session.run(traversal_query, **params)
                for rec in results:
                    _add_node_and_paths(rec, all_nodes, all_paths)

    return all_nodes, all_paths


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BÆ¯á»šC 3: PAGERANK RANKING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def rank_nodes(nodes: list[dict], top_k: int = TOP_K,
               negated_keywords: list[str] | None = None,
               asked_label: str | None = None) -> list[dict]:
    """
    Xáº¿p háº¡ng nodes theo PageRank vá»›i chiáº¿n lÆ°á»£c 2 bucket:
    - Bucket 1 (Æ°u tiÃªn): nodes khá»›p asked_label â†’ láº¥y tá»‘i Ä‘a top_k * 2 / 3
    - Bucket 2 (context): cÃ¡c nodes cÃ²n láº¡i â†’ láº¥y pháº§n cÃ²n láº¡i
    Lá»c bá» nodes khá»›p negated_keywords vÃ  dedup theo (label, name).
    """
    negated_keywords = [kw.lower() for kw in (negated_keywords or [])]

    def score(n: dict) -> float:
        pr   = n.get("pagerank") or 0.0
        hops = n.get("hops")     or 1
        return pr / hops

    # Dedup toÃ n bá»™ trÆ°á»›c (Æ°u tiÃªn báº£n cÃ³ hops nhá» nháº¥t = gáº§n seed nháº¥t)
    seen_keys: dict = {}
    for n in nodes:
        key = (n.get("label", ""), n.get("name", ""))
        if key not in seen_keys or (n.get("hops") or 99) < (seen_keys[key].get("hops") or 99):
            seen_keys[key] = n

    deduped = list(seen_keys.values())

    # Lá»c thá»±c thá»ƒ bá»‹ phá»§ Ä‘á»‹nh
    if negated_keywords:
        deduped = [
            n for n in deduped
            if not any(neg in (n.get("name") or "").lower() for neg in negated_keywords)
        ]

    # TÃ¡ch 2 bucket
    if asked_label and asked_label != "UNKNOWN":
        target_nodes  = [n for n in deduped if n.get("label") == asked_label]
        context_nodes = [n for n in deduped if n.get("label") != asked_label]

        target_nodes.sort(key=score, reverse=True)
        context_nodes.sort(key=score, reverse=True)

        target_slots  = max(top_k // 2, min(len(target_nodes), top_k))
        context_slots = top_k - min(len(target_nodes), target_slots)

        result = target_nodes[:target_slots] + context_nodes[:context_slots]
        print(f"  [rank] target({asked_label})={len(target_nodes)} dung {min(len(target_nodes), target_slots)} | "
              f"context={len(context_nodes)} dung {min(len(context_nodes), context_slots)}")
    else:
        deduped.sort(key=score, reverse=True)
        result = deduped[:top_k]

    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LLM: Extract intent + Generate answer
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_answer(ai_client: OpenAI, question: str,
                    ranked_nodes: list[dict], traversal_paths: list[dict],
                    intent: dict) -> str:
    """
    Tá»•ng há»£p cÃ¢u tráº£ lá»i tá»« KG context + intent constraints.
    """
    context = json.dumps({
        "ranked_results": ranked_nodes,
        "traversal_paths": traversal_paths[:60],
    }, ensure_ascii=False, indent=2)

    # Láº¥y rÃ ng buá»™c quan há»‡ theo loáº¡i cÃ¢u há»i
    constraint = get_relationship_constraint(intent)

    # Bá»• sung ghi chÃº phá»§ Ä‘á»‹nh náº¿u cÃ³
    negated = intent.get("negated_keywords", [])
    if negated:
        constraint += (
            f"\n\nLÆ¯U Ã PHá»¦ Äá»ŠNH: NgÆ°á»i dÃ¹ng Ä‘á» cáº­p há» KHÃ”NG giá»i / khÃ´ng thÃ­ch: {negated}. "
            "Loáº¡i bá» cÃ¡c mÃ´n/ká»¹ nÄƒng/ngÃ nh nÃ y khá»i gá»£i Ã½. "
            "Thay vÃ o Ä‘Ã³ gá»£i Ã½ nhá»¯ng lá»±a chá»n phÃ¹ há»£p hÆ¡n."
        )

    system_prompt = ANSWER_SYSTEM_BASE.format(
        schema=SCHEMA_DESC,
        constraint=constraint,
    )

    # Cáº£nh bÃ¡o vá» dá»¯ liá»‡u trá»‘ng
    no_data_hint = ""
    if not ranked_nodes:
        no_data_hint = (
            "\n[Cáº¢NH BÃO: KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u liÃªn quan trong Knowledge Graph. "
            "ThÃ´ng bÃ¡o lá»‹ch sá»± ráº±ng dá»¯ liá»‡u chÆ°a Ä‘á»§, khÃ´ng bá»‹a thÃ´ng tin.]"
        )

    response = ai_client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user",   "content": (
                f"CÃ¢u há»i: {question}\n\n"
                f"Káº¿t quáº£ Knowledge Graph (Ä‘Ã£ xáº¿p háº¡ng PageRank):\n{context}"
                f"{no_data_hint}\n\n"
                "HÆ°á»›ng dáº«n tráº£ lá»i:\n"
                "- DÃ¹ng Táº¤T Cáº¢ thÃ´ng tin cÃ³ trong káº¿t quáº£ trÃªn Ä‘á»ƒ tráº£ lá»i.\n"
                "- Náº¿u cÃ³ node SUBJECT vá»›i code (mÃ£ mÃ´n) â†’ nháº¯c Ä‘áº¿n tÃªn mÃ´n vÃ  mÃ£ mÃ´n.\n"
                "- Náº¿u cÃ³ node CAREER â†’ nháº¯c Ä‘áº¿n nghá» nghiá»‡p cá»¥ thá»ƒ.\n"
                "- Náº¿u cÃ³ node SKILL â†’ liá»‡t kÃª ká»¹ nÄƒng.\n"
                "- KHÃ”NG nÃ³i 'dá»¯ liá»‡u chÆ°a Ä‘á»§' náº¿u Ä‘Ã£ cÃ³ nodes trong káº¿t quáº£.\n"
                "- Tráº£ lá»i tá»± nhiÃªn báº±ng tiáº¿ng Viá»‡t, kÃ¨m mÃ£ ngÃ nh/mÃ£ mÃ´n khi cÃ³:"
            )},
        ],
        temperature=0.3,
    )
    return response.choices[0].message.content.strip()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PIPELINE CHÃNH
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def fetch_seed_entities(driver, keywords: list[str], mentioned_labels: list[str]) -> list[dict]:
    """
    Fetch trá»±c tiáº¿p cÃ¡c seed entity (MAJOR/CAREER/...) khá»›p keyword.
    Äáº£m báº£o code/name cá»§a thá»±c thá»ƒ gá»‘c luÃ´n cÃ³ trong context dÃ¹ bá»‹ ranking Ä‘áº©y xuá»‘ng.
    """
    if not keywords or not mentioned_labels:
        return []
    label_filter = " OR ".join([f"n:{lbl}" for lbl in mentioned_labels])
    results = []
    with driver.session() as session:
        for kw in keywords:
            rows = session.run(f"""
                MATCH (n)
                WHERE ({label_filter})
                  AND toLower(n.name) CONTAINS toLower($kw)
                RETURN n.name AS name, labels(n)[0] AS label,
                       n.code AS code, n.pagerank AS pagerank,
                       n.community_id AS community_id
                LIMIT 3
            """, kw=kw).data()
            for r in rows:
                results.append({
                    "name": r["name"], "label": r["label"],
                    "code": r["code"], "pagerank": r["pagerank"],
                    "community_id": r["community_id"], "hops": 0,
                })
    return results

def ask(driver, ai_client: OpenAI, question: str,
        query_id: str | None = None) -> dict:
    if query_id is None:
        query_id = "q" + uuid.uuid4().hex[:6]

    print(f"\n{'='*60}")
    print(f"Q [{query_id}]: {question}")

    # â”€â”€ BÆ°á»›c 1: Extract intent (keywords + labels + negation) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    intent = extract_query_intent(ai_client, question, memory)
    keywords         = intent["keywords"]
    negated_keywords = intent["negated_keywords"]
    print(f"  Keywords: {keywords}")
    print(f"  Intent: mentioned={intent['mentioned_labels']} asked={intent['asked_label']} "
          f"negated={negated_keywords} comparison={intent['is_comparison']}")

    # â”€â”€ BÆ°á»›c 1b: Fetch seed entities (Ä‘áº£m báº£o code luÃ´n cÃ³ trong context) â”€â”€â”€â”€â”€
    seed_entities = fetch_seed_entities(driver, keywords, intent.get("mentioned_labels", []))
    print(f"  Seed entities: {[(e['name'], e['code']) for e in seed_entities]}")

    # â”€â”€ BÆ°á»›c 2: Community Detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    community_ids = find_relevant_communities(driver, keywords)
    print(f"  Communities: {community_ids}")

    # â”€â”€ BÆ°á»›c 3: Multi-hop BFS Traversal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    raw_nodes, traversal_paths = multihop_traversal(
        driver, keywords, community_ids, max_hops=MAX_HOPS, intent=intent
    )
    print(f"  BFS nodes found: {len(raw_nodes)}  |  paths: {len(traversal_paths)}")

    # â”€â”€ BÆ°á»›c 4: PageRank Ranking (cÃ³ lá»c thá»±c thá»ƒ phá»§ Ä‘á»‹nh) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ranked_nodes = rank_nodes(raw_nodes, top_k=TOP_K, negated_keywords=negated_keywords,
                              asked_label=intent.get("asked_label"))
    print(f"  After PageRank ranking (top {TOP_K}): {len(ranked_nodes)} nodes")
    if ranked_nodes:
        top3 = [(n["name"], round(n.get("pagerank") or 0, 4)) for n in ranked_nodes[:3]]
        print(f"  Top 3: {top3}")

    # â”€â”€ BÆ°á»›c 4b: Inject seed entities vÃ o Ä‘áº§u context (Ä‘áº£m báº£o code luÃ´n cÃ³) â”€
    # Dedup: loáº¡i seed_entities Ä‘Ã£ cÃ³ trong ranked_nodes
    ranked_names = {n.get("name") for n in ranked_nodes}
    extra_seeds  = [e for e in seed_entities if e.get("name") not in ranked_names]
    context_nodes = extra_seeds + ranked_nodes

    # â”€â”€ BÆ°á»›c 5: LLM tá»•ng há»£p cÃ¢u tráº£ lá»i (cÃ³ intent constraints) â”€â”€â”€â”€
    answer = generate_answer(
        ai_client, question, context_nodes, traversal_paths,
        intent=intent
    )
    print(f"\nA: {answer}")

    qa_record = {
        "query_id":            query_id,
        "query":               question,
        "generated_answer":    answer,
        "keywords":            keywords,
        "intent":              intent,
        "communities_covered": community_ids,
        "context_text":        json.dumps(ranked_nodes, ensure_ascii=False),
        "retrieved_nodes": [
            {
                "node_id":  f"node{i+1:03d}",
                "content":  json.dumps(n, ensure_ascii=False),
                "score":    round(n.get("pagerank") or 0, 6),
                "entities": [n.get("name", "")],
            }
            for i, n in enumerate(ranked_nodes)
        ],
        "traversal_path":      traversal_paths[:20],
        "timestamp":           datetime.datetime.now().isoformat(),
        "algorithm": {
            "community_detection": "Louvain (NetworkX)",
            "traversal":           f"BFS multi-hop (max_hops={MAX_HOPS})",
            "ranking":             "PageRank (damping=0.85) + negation filter",
        },
    }

    return qa_record


# â”€â”€ Neo4j â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_driver():
    return GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))


# â”€â”€ Interactive loop vá»›i Memory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def interactive_loop(driver, ai_client: OpenAI):
    print("\nğŸ“ Knowledge Graph Chatbot (NEU)")
    print(f"Pipeline: Intent Detection â†’ Community â†’ BFS (max={MAX_HOPS}) â†’ PageRank â†’ LLM")
    print("GÃµ cÃ¢u há»i. Nháº­p 'exit' Ä‘á»ƒ thoÃ¡t.\n")

    counter = 1
    while True:
        try:
            question = input("Báº¡n: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nTáº¡m biá»‡t!")
            break

        if not question:
            continue

        if question.lower() in ("exit", "quit", "thoat", "thoÃ¡t"):
            print("Táº¡m biá»‡t!")
            break

        qa_record = ask(
            driver, ai_client, question,
            query_id=f"q{counter:03d}"
        )

        counter += 1


def main():
    print("Starting KG Chatbot...")
    ai_client = OpenAI(api_key=OPENAI_API_KEY)
    driver    = get_driver()

    try:
        print("\nBáº¡n cÃ³ muá»‘n cháº¡y Community Detection + PageRank khÃ´ng?")
        print("(Chá»‰ cáº§n cháº¡y 1 láº§n sau khi load dá»¯ liá»‡u lÃªn Neo4j)")
        ans = input("Nháº­p 'yes' Ä‘á»ƒ cháº¡y, Enter Ä‘á»ƒ bá» qua: ").strip().lower()
        if ans == "yes":
            setup_graph_algorithms(driver)

        interactive_loop(driver, ai_client)
    finally:
        driver.close()


if __name__ == "__main__":
    main()