"""
Script 3: Knowledge Graph Q&A Chatbot"""

import os
import json
import uuid
import datetime
from pathlib import Path
from neo4j import GraphDatabase
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NEO4J_URI      = os.getenv("DB_URL",)
NEO4J_USERNAME = os.getenv("DB_USER")
NEO4J_PASSWORD = os.getenv("DB_PASSWORD")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL   = os.getenv("OPENAI_MODEL")

MAX_HOPS    = int(os.getenv("MAX_HOPS"))   # giá»›i háº¡n BFS
TOP_K       = int(os.getenv("TOP_K"))  # sá»‘ node tráº£ vá» sau ranking
LOG_DIR     = Path("./qa_logs")   # dÃ¹ng khi cháº¡y evaluation
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SCHEMA_DESC = """
Nodes: MAJOR{name,code,community_id,pagerank}, SUBJECT{name,code,community_id,pagerank},
       SKILL{name,community_id,pagerank}, CAREER{name,community_id,pagerank},
       TEACHER{name,community_id}, DOCUMENT{name,docid,doctype}
Relationships:
  (MAJOR)-[:OFFERS]->(SUBJECT)
  (TEACHER)-[:TEACH]->(SUBJECT)
  (SUBJECT)-[:PROVIDES]->(SKILL)
  (CAREER)-[:REQUIRES]->(SKILL)
  (SUBJECT)-[:PREREQUISITE_FOR]->(SUBJECT)
  (MAJOR)-[:LEADS_TO]->(CAREER)
  (*)-[:MENTIONED_IN]->(DOCUMENT)
All name values are UPPERCASE Vietnamese.
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BÆ¯á»šC 0: SETUP â€” Cháº¡y Community Detection + PageRank (offline, 1 láº§n)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def setup_graph_algorithms(driver):
    """
    Community Detection (Louvain) + PageRank tÃ­nh báº±ng NetworkX (Python),
    sau Ä‘Ã³ ghi community_id vÃ  pagerank ngÆ°á»£c lÃªn Neo4j.
    KhÃ´ng cáº§n GDS plugin â€” hoáº¡t Ä‘á»™ng trÃªn Aura Free.
    Chá»‰ cáº§n cháº¡y 1 láº§n sau khi load xong dá»¯ liá»‡u.
    """
    try:
        import networkx as nx
        from networkx.algorithms.community import louvain_communities
    except ImportError:
        print("  CÃ i networkx: pip install networkx")
        return

    print("\n[Setup] Pull graph tá»« Neo4j â†’ tÃ­nh Louvain + PageRank báº±ng NetworkX...")

    G = nx.Graph()
    node_labels = {}   # node_name â†’ label

    with driver.session() as session:
        # â”€â”€ Pull toÃ n bá»™ nodes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        nodes = session.run("""
            MATCH (n)
            WHERE n:MAJOR OR n:SUBJECT OR n:SKILL OR n:CAREER OR n:TEACHER
            RETURN n.name AS name, labels(n)[0] AS label
        """).data()
        for row in nodes:
            if row["name"]:
                G.add_node(row["name"])
                node_labels[row["name"]] = row["label"]

        # â”€â”€ Pull toÃ n bá»™ relationships â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        rels = session.run("""
            MATCH (a)-[r]->(b)
            WHERE (a:MAJOR OR a:SUBJECT OR a:SKILL OR a:CAREER OR a:TEACHER)
              AND (b:MAJOR OR b:SUBJECT OR b:SKILL OR b:CAREER OR b:TEACHER)
              AND a.name IS NOT NULL AND b.name IS NOT NULL
            RETURN a.name AS src, b.name AS tgt
        """).data()
        for row in rels:
            G.add_edge(row["src"], row["tgt"])

    print(f"  Graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges")

    # â”€â”€ Community Detection: Louvain trong tá»«ng label group â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Chiáº¿n lÆ°á»£c: má»—i label (TEACHER, SKILL, CAREER, MAJOR, SUBJECT) lÃ  1 "super-community"
    # BÃªn trong má»—i label, dÃ¹ng Louvain Ä‘á»ƒ tÃ¬m sub-community
    # â†’ Äáº£m báº£o TEACHER khÃ´ng bá»‹ láº«n vÃ o community cá»§a SUBJECT
    print("  Cháº¡y Louvain community detection (per-label)...")

    LABEL_BASE_ID = {
        "TEACHER": 0,
        "SKILL":   1000,
        "CAREER":  2000,
        "MAJOR":   3000,
        "SUBJECT": 4000,
    }

    node_community = {}

    for label, base_id in LABEL_BASE_ID.items():
        # Láº¥y cÃ¡c node thuá»™c label nÃ y
        label_nodes = [n for n, lbl in node_labels.items() if lbl == label]
        if not label_nodes:
            continue

        # Táº¡o subgraph chá»‰ gá»“m cÃ¡c node cÃ¹ng label
        subG = G.subgraph(label_nodes).copy()

        if subG.number_of_edges() > 0:
            # CÃ³ edges â†’ dÃ¹ng Louvain Ä‘á»ƒ tÃ¬m sub-community
            sub_communities = louvain_communities(subG, seed=42)
            for sub_cid, community in enumerate(sub_communities):
                for node in community:
                    node_community[node] = base_id + sub_cid
        else:
            # KhÃ´ng cÃ³ edges giá»¯a cÃ¡c node cÃ¹ng label â†’ má»—i node 1 community
            for i, node in enumerate(label_nodes):
                node_community[node] = base_id + i

    total_communities = len(set(node_community.values()))
    print(f"  TÃ¬m tháº¥y {total_communities} communities "
          f"(TEACHER:0xxx, SKILL:1xxx, CAREER:2xxx, MAJOR:3xxx, SUBJECT:4xxx)")

    # â”€â”€ PageRank â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("  Cháº¡y PageRank...")
    pagerank = nx.pagerank(G, alpha=0.85, max_iter=100)

    # â”€â”€ Ghi ngÆ°á»£c lÃªn Neo4j â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("  Ghi community_id + pagerank lÃªn Neo4j...")
    with driver.session() as session:
        BATCH_SIZE = 500
        items = list(node_community.items())
        for i in range(0, len(items), BATCH_SIZE):
            batch = [
                {"name": name, "cid": cid, "pr": round(pagerank.get(name, 0.0), 8)}
                for name, cid in items[i:i+BATCH_SIZE]
            ]
            session.run("""
                UNWIND $batch AS row
                MATCH (n) WHERE n.name = row.name
                SET n.community_id = row.cid,
                    n.pagerank      = row.pr
            """, batch=batch)

    total_written = len(node_community)
    print(f"  ÄÃ£ ghi {total_written} nodes")
    print("[Setup] Xong. community_id vÃ  pagerank Ä‘Ã£ Ä‘Æ°á»£c ghi vÃ o graph.\n")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BÆ¯á»šC 1: COMMUNITY DETECTION â€” TÃ¬m community liÃªn quan Ä‘áº¿n cÃ¢u há»i
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def find_relevant_communities(driver, keywords: list[str]) -> list[int]:
    """
    TÃ¬m community_id cá»§a cÃ¡c node cÃ³ tÃªn chá»©a keyword.
    Tráº£ vá» danh sÃ¡ch community_id liÃªn quan.
    """
    if not keywords:
        return []

    with driver.session() as session:
        community_ids = set()
        for kw in keywords:
            result = session.run("""
                MATCH (n)
                WHERE (n:MAJOR OR n:SUBJECT OR n:SKILL OR n:CAREER OR n:TEACHER)
                  AND toLower(n.name) CONTAINS toLower($kw)
                  AND n.community_id IS NOT NULL
                RETURN DISTINCT n.community_id AS cid
                LIMIT 5
            """, kw=kw)
            for rec in result:
                community_ids.add(rec["cid"])

    return list(community_ids)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BÆ¯á»šC 2: MULTI-HOP TRAVERSAL â€” BFS trong community, giá»›i háº¡n max_hops
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def multihop_traversal(driver, keywords: list[str],
                       community_ids: list[int],
                       max_hops: int = MAX_HOPS) -> tuple[list[dict], list[dict]]:
    """
    BFS traversal tá»« cÃ¡c seed node (khá»›p keyword) má»Ÿ rá»™ng tá»‘i Ä‘a max_hops bÆ°á»›c.
    Náº¿u cÃ³ community_id â†’ chá»‰ tÃ¬m trong community Ä‘Ã³.
    Tráº£ vá» (nodes, traversal_paths).
    """
    all_nodes  = []
    all_paths  = []
    seen_names = set()

    with driver.session() as session:
        for kw in keywords:
            # TÃ¬m seed nodes
            seed_query = """
                MATCH (seed)
                WHERE (seed:MAJOR OR seed:SUBJECT OR seed:SKILL OR seed:CAREER OR seed:TEACHER)
                  AND toLower(seed.name) CONTAINS toLower($kw)
                RETURN seed
                LIMIT 3
            """
            seeds = [rec["seed"] for rec in session.run(seed_query, kw=kw)]

            for seed in seeds:
                seed_name = seed.get("name", "")
                if seed_name in seen_names:
                    continue
                seen_names.add(seed_name)

                # BFS multi-hop: traversal tá»›i max_hops bÆ°á»›c
                # Lá»c theo community_id náº¿u cÃ³
                community_filter = ""
                params: dict = {"seed_name": seed_name, "max_hops": max_hops}

                if community_ids:
                    community_filter = "AND (n.community_id IN $cids OR n.community_id IS NULL)"
                    params["cids"] = community_ids

                traversal_query = f"""
                    MATCH path = (start)-[*1..{max_hops}]-(n)
                    WHERE start.name = $seed_name
                      AND (n:MAJOR OR n:SUBJECT OR n:SKILL OR n:CAREER OR n:TEACHER)
                      {community_filter}
                    WITH n, path,
                         [r IN relationships(path) | type(r)] AS rel_types,
                         [x IN nodes(path) | x.name]          AS node_names
                    RETURN DISTINCT
                        n.name         AS name,
                        labels(n)[0]   AS label,
                        n.code         AS code,
                        n.pagerank     AS pagerank,
                        n.community_id AS community_id,
                        rel_types,
                        node_names,
                        length(path)   AS hops
                    ORDER BY hops ASC
                    LIMIT 50
                """
                results = session.run(traversal_query, **params)

                for rec in results:
                    node_info = {
                        "name":         rec["name"],
                        "label":        rec["label"],
                        "code":         rec["code"],
                        "pagerank":     rec["pagerank"],
                        "community_id": rec["community_id"],
                        "hops":         rec["hops"],
                    }
                    all_nodes.append(node_info)

                    # Build traversal path log
                    node_names = rec["node_names"]
                    rel_types  = rec["rel_types"]
                    for i, rel in enumerate(rel_types):
                        path_entry = {
                            "from":     node_names[i]   if i < len(node_names) else "",
                            "to":       node_names[i+1] if i+1 < len(node_names) else "",
                            "relation": rel,
                            "hop":      i + 1,
                        }
                        all_paths.append(path_entry)

    return all_nodes, all_paths


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BÆ¯á»šC 3: PAGERANK RANKING â€” Xáº¿p háº¡ng vÃ  lá»c top-K node quan trá»ng nháº¥t
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def rank_nodes(nodes: list[dict], top_k: int = TOP_K) -> list[dict]:
    """
    Xáº¿p háº¡ng nodes theo PageRank (Ä‘Ã£ tÃ­nh sáºµn trÃªn Neo4j).
    Æ¯u tiÃªn: node cÃ³ pagerank cao + hop Ã­t (gáº§n seed).
    """
    def score(n: dict) -> float:
        pr   = n.get("pagerank") or 0.0
        hops = n.get("hops")     or 1
        # Score = pagerank / hops  â†’ node quan trá»ng + gáº§n seed Ä‘Æ°á»£c Æ°u tiÃªn
        return pr / hops

    ranked = sorted(nodes, key=score, reverse=True)

    # Dedup theo name
    seen  = set()
    dedup = []
    for n in ranked:
        key = (n.get("label",""), n.get("name",""))
        if key not in seen:
            seen.add(key)
            dedup.append(n)

    return dedup[:top_k]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LLM: Extract keywords + Generate answer
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extract_keywords(ai_client: OpenAI, question: str) -> list[str]:
    """Extract cÃ¡c tá»« khoÃ¡ thá»±c thá»ƒ tá»« cÃ¢u há»i Ä‘á»ƒ lÃ m seed BFS."""
    response = ai_client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[
            {"role": "system", "content": (
                "Extract entity keywords from the user question for a university Knowledge Graph search. "
                "Return JSON: {\"keywords\": [\"keyword1\", \"keyword2\", ...]}. "
                "Keywords should be names of: careers, subjects, skills, majors, or teachers. "
                "Keep original Vietnamese text."
            )},
            {"role": "user", "content": question},
        ],
        temperature=0,
        response_format={"type": "json_object"},
    )
    parsed = json.loads(response.choices[0].message.content)
    return parsed.get("keywords", [])


def generate_answer(ai_client: OpenAI, question: str,
                    ranked_nodes: list[dict], traversal_paths: list[dict]) -> str:
    context = json.dumps({
        "ranked_results": ranked_nodes,
        "traversal_paths": traversal_paths[:30],
    }, ensure_ascii=False, indent=2)

    response = ai_client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[
            {"role": "system", "content": (
                "Báº¡n lÃ  trá»£ lÃ½ tÆ° váº¥n há»c thuáº­t. Tá»•ng há»£p cÃ¢u tráº£ lá»i rÃµ rÃ ng báº±ng tiáº¿ng Viá»‡t "
                "tá»« káº¿t quáº£ Knowledge Graph Ä‘Ã£ xáº¿p háº¡ng theo PageRank. "
                "Æ¯u tiÃªn cÃ¡c node cÃ³ pagerank cao. Náº¿u khÃ´ng cÃ³ dá»¯ liá»‡u, thÃ´ng bÃ¡o lá»‹ch sá»±.\n"
                f"{SCHEMA_DESC}\n\n"
                "QUY Táº®C Äá»ŠNH Dáº NG Káº¾T QUáº¢:\n"
                "- Khi Ä‘á» cáº­p Ä‘áº¿n MAJOR (chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o / ngÃ nh há»c): "
                "luÃ´n viáº¿t theo dáº¡ng 'TÃªn ngÃ nh (MÃ£ ngÃ nh)'. "
                "VÃ­ dá»¥: 'CÃ´ng nghá»‡ thÃ´ng tin (7480201)', 'Ká»¹ thuáº­t pháº§n má»m (7480103)'.\n"
                "- Khi Ä‘á» cáº­p Ä‘áº¿n SUBJECT (mÃ´n há»c): "
                "luÃ´n viáº¿t theo dáº¡ng 'TÃªn mÃ´n (MÃ£ mÃ´n)'. "
                "VÃ­ dá»¥: 'CÆ¡ sá»Ÿ dá»¯ liá»‡u (IT001)'.\n"
                "- Náº¿u khÃ´ng cÃ³ mÃ£ trong dá»¯ liá»‡u thÃ¬ chá»‰ ghi tÃªn, khÃ´ng bá»‹a mÃ£."
            )},
            {"role": "user", "content": (
                f"CÃ¢u há»i: {question}\n\n"
                f"Káº¿t quáº£ Knowledge Graph (Ä‘Ã£ xáº¿p háº¡ng PageRank):\n{context}\n\n"
                "HÃ£y tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, nhá»› kÃ¨m mÃ£ ngÃ nh/mÃ£ mÃ´n khi cÃ³:"
            )},
        ],
        temperature=0.3,
    )
    return response.choices[0].message.content.strip()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PIPELINE CHÃNH
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def ask(driver, ai_client: OpenAI, question: str, query_id: str | None = None) -> dict:
    if query_id is None:
        query_id = "q" + uuid.uuid4().hex[:6]

    print(f"\n{'='*60}")
    print(f"Q [{query_id}]: {question}")

    # â”€â”€ BÆ°á»›c 1: Extract keywords â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    keywords = extract_keywords(ai_client, question)
    print(f"  Keywords: {keywords}")

    # â”€â”€ BÆ°á»›c 2: Community Detection â€” thu háº¹p khÃ´ng gian tÃ¬m kiáº¿m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    community_ids = find_relevant_communities(driver, keywords)
    print(f"  Communities: {community_ids}")

    # â”€â”€ BÆ°á»›c 3: Multi-hop BFS Traversal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    raw_nodes, traversal_paths = multihop_traversal(
        driver, keywords, community_ids, max_hops=MAX_HOPS
    )
    print(f"  BFS nodes found: {len(raw_nodes)}  |  paths: {len(traversal_paths)}")

    # â”€â”€ BÆ°á»›c 4: PageRank Ranking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ranked_nodes = rank_nodes(raw_nodes, top_k=TOP_K)
    print(f"  After PageRank ranking (top {TOP_K}): {len(ranked_nodes)} nodes")
    if ranked_nodes:
        top3 = [(n["name"], round(n.get("pagerank") or 0, 4)) for n in ranked_nodes[:3]]
        print(f"  Top 3: {top3}")

    # â”€â”€ BÆ°á»›c 5: LLM tá»•ng há»£p cÃ¢u tráº£ lá»i â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    answer = generate_answer(ai_client, question, ranked_nodes, traversal_paths)
    print(f"\nA: {answer}")

    # â”€â”€ Build record (tráº£ vá» Ä‘á»ƒ eval pipeline dÃ¹ng, khÃ´ng tá»± Ä‘á»™ng lÆ°u file) â”€â”€
    qa_record = {
        "query_id":            query_id,
        "query":               question,
        "generated_answer":    answer,
        "keywords":            keywords,
        "communities_covered": community_ids,
        "context_text":        json.dumps(ranked_nodes, ensure_ascii=False),
        "retrieved_nodes": [
            {
                "node_id":  f"node{i+1:03d}",
                "content":  json.dumps(n, ensure_ascii=False),
                "score":    round(n.get("pagerank") or 0, 6),
                "entities": [n.get("name","")],
            }
            for i, n in enumerate(ranked_nodes)
        ],
        "traversal_path":      traversal_paths[:20],
        "timestamp":           datetime.datetime.now().isoformat(),
        "algorithm": {
            "community_detection": "Louvain (Neo4j GDS)",
            "traversal":           f"BFS multi-hop (max_hops={MAX_HOPS})",
            "ranking":             "PageRank (damping=0.85)",
        },
    }

    return qa_record


# â”€â”€ Neo4j â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_driver():
    return GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))


# â”€â”€ Interactive loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def interactive_loop(driver, ai_client: OpenAI):
    print("\nğŸ“ Knowledge Graph Chatbot (NEU)")
    print(f"Pipeline: Community Detection â†’ BFS multi-hop (max={MAX_HOPS}) â†’ PageRank â†’ LLM")
    print("GÃµ cÃ¢u há»i. Nháº­p 'exit' Ä‘á»ƒ thoÃ¡t.\n")

    counter = 1
    while True:
        try:
            question = input("Báº¡n: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nTáº¡m biá»‡t!")
            break
        if not question:
            continue
        if question.lower() in ("exit", "quit", "thoat", "thoÃ¡t"):
            print("Táº¡m biá»‡t!")
            break
        ask(driver, ai_client, question, query_id=f"q{counter:03d}")
        counter += 1


def main():
    print("Starting KG Chatbot...")
    ai_client = OpenAI(api_key=OPENAI_API_KEY)
    driver    = get_driver()

    try:
        # Há»i ngÆ°á»i dÃ¹ng cÃ³ muá»‘n cháº¡y setup khÃ´ng
        print("\nBáº¡n cÃ³ muá»‘n cháº¡y Community Detection + PageRank khÃ´ng?")
        print("(Chá»‰ cáº§n cháº¡y 1 láº§n sau khi load dá»¯ liá»‡u lÃªn Neo4j)")
        ans = input("Nháº­p 'yes' Ä‘á»ƒ cháº¡y, Enter Ä‘á»ƒ bá» qua: ").strip().lower()
        if ans == "yes":
            setup_graph_algorithms(driver)

        interactive_loop(driver, ai_client)
    finally:
        driver.close()


if __name__ == "__main__":
    main()